{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov3_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhP2g8QlECuFEMUSBgU9vt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuYouge/colab/blob/master/yolov3_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKWpC-67XwU3",
        "colab_type": "text"
      },
      "source": [
        "# 训练流程"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFv6Y0lVX3XR",
        "colab_type": "text"
      },
      "source": [
        "## 初始化环境"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgKnXCe1XtAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/yolov3_test\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n",
        "\n",
        "%cd yolov3-tf2/\n",
        "\n",
        "# !pip install opencv-python==4.1.1.26 lxml tqdm -e .\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZlVWlCcdTe",
        "colab_type": "text"
      },
      "source": [
        "## 开始训练\n",
        "以完整的yolo-v3为例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCnLrtvJc1PS",
        "colab_type": "text"
      },
      "source": [
        "### 交互模式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTYja-lhcr_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ReduceLROnPlateau,\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    TensorBoard\n",
        ")\n",
        "# from yolov3_tf2.models import (\n",
        "#     YoloV3, YoloV3Tiny, YoloLoss,\n",
        "#     yolo_anchors, yolo_anchor_masks,\n",
        "#     yolo_tiny_anchors, yolo_tiny_anchor_masks\n",
        "# )\n",
        "from yolov3_tf2.utils import freeze_all\n",
        "import yolov3_tf2.dataset as dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLPCsWfScyju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flags.DEFINE_string('dataset', '', 'path to dataset')\n",
        "flags.DEFINE_string('val_dataset', '', 'path to validation dataset')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n",
        "                    'path to weights file')\n",
        "flags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\n",
        "flags.DEFINE_enum('mode', 'fit', ['fit', 'eager_fit', 'eager_tf'],\n",
        "                  'fit: model.fit, '\n",
        "                  'eager_fit: model.fit(run_eagerly=True), '\n",
        "                  'eager_tf: custom GradientTape')\n",
        "flags.DEFINE_enum('transfer', 'none',\n",
        "                  ['none', 'darknet', 'no_output', 'frozen', 'fine_tune'],\n",
        "                  'none: Training from scratch, '\n",
        "                  'darknet: Transfer darknet, '\n",
        "                  'no_output: Transfer all but output, '\n",
        "                  'frozen: Transfer and freeze all, '\n",
        "                  'fine_tune: Transfer all and freeze darknet only')\n",
        "flags.DEFINE_integer('size', 416, 'image size')\n",
        "flags.DEFINE_integer('epochs', 2, 'number of epochs')\n",
        "flags.DEFINE_integer('batch_size', 8, 'batch size')\n",
        "flags.DEFINE_float('learning_rate', 1e-3, 'learning rate')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "flags.DEFINE_integer('weights_num_classes', None, 'specify num class for `weights` file if different, '\n",
        "                     'useful in transfer learning with different number of classes')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQPsHHfZcn5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAGS.dataset = './data/voc_train.tfrecord'\n",
        "FLAGS.val_dataset = './data/voc_val.tfrecord'\n",
        "FLAGS.classes = './data/voc2012.names'\n",
        "FLAGS.num_classes = 20\n",
        "FLAGS.mode = 'it' \n",
        "FLAGS.transfer = 'no_output'\n",
        "FLAGS.batch_size = 16\n",
        "FLAGS.epochs = 3\n",
        "FLAGS.weights = './checkpoints/yolov3.tf'\n",
        "FLAGS.weights_num_classes = 80\n",
        "\n",
        "app._run_init(['convert'], app.parse_flags_with_usage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGNqSfFph9aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义网络\n",
        "# def YoloV3(size=None, channels=3, anchors=yolo_anchors,\n",
        "#            masks=yolo_anchor_masks, classes=80, training=False):\n",
        "from tensorflow.keras.layers import (\n",
        "    Add,\n",
        "    Concatenate,\n",
        "    Conv2D,\n",
        "    Input,\n",
        "    Lambda,\n",
        "    LeakyReLU,\n",
        "    MaxPool2D,\n",
        "    UpSampling2D,\n",
        "    ZeroPadding2D,\n",
        ")\n",
        "\n",
        "from yolov3_tf2.models import Darknet\n",
        "from yolov3_tf2.models import YoloOutput\n",
        "from yolov3_tf2.models import YoloConv\n",
        "from yolov3_tf2.models import yolo_nms\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def YoloV3(size, channels, anchors, masks, classes, training):\n",
        "    x = inputs = Input([size, size, channels], name='input')\n",
        "\n",
        "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
        "\n",
        "    x = YoloConv(512, name='yolo_conv_0')(x)\n",
        "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
        "\n",
        "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
        "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
        "\n",
        "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
        "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
        "\n",
        "    if training:\n",
        "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
        "\n",
        "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
        "                     name='yolo_boxes_0')(output_0)\n",
        "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
        "                     name='yolo_boxes_1')(output_1)\n",
        "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
        "                     name='yolo_boxes_2')(output_2)\n",
        "\n",
        "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
        "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
        "\n",
        "    return Model(inputs, outputs, name='yolov3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofvW3_USiHx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义损失函数\n",
        "# def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
        "\n",
        "from yolov3_tf2.models import yolo_boxes\n",
        "from yolov3_tf2.utils import broadcast_iou\n",
        "\n",
        "from tensorflow.keras.losses import (\n",
        "    binary_crossentropy,\n",
        "    sparse_categorical_crossentropy\n",
        ")\n",
        "\n",
        "def YoloLoss(anchors, classes, ignore_thresh):\n",
        "    def yolo_loss(y_true, y_pred):\n",
        "        # 1. transform all pred outputs\n",
        "        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
        "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(\n",
        "            y_pred, anchors, classes)\n",
        "        pred_xy = pred_xywh[..., 0:2]\n",
        "        pred_wh = pred_xywh[..., 2:4]\n",
        "\n",
        "        # 2. transform all true outputs\n",
        "        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n",
        "        true_box, true_obj, true_class_idx = tf.split(\n",
        "            y_true, (4, 1, 1), axis=-1)\n",
        "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
        "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
        "\n",
        "        # give higher weights to small boxes\n",
        "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
        "\n",
        "        # 3. inverting the pred box equations\n",
        "        grid_size = tf.shape(y_true)[1]\n",
        "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
        "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
        "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
        "            tf.cast(grid, tf.float32)\n",
        "        true_wh = tf.math.log(true_wh / anchors)\n",
        "        true_wh = tf.where(tf.math.is_inf(true_wh),\n",
        "                           tf.zeros_like(true_wh), true_wh)\n",
        "\n",
        "        # 4. calculate all masks\n",
        "        obj_mask = tf.squeeze(true_obj, -1)\n",
        "        # ignore false positive when iou is over threshold\n",
        "        best_iou = tf.map_fn(\n",
        "            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(\n",
        "                x[1], tf.cast(x[2], tf.bool))), axis=-1),\n",
        "            (pred_box, true_box, obj_mask),\n",
        "            tf.float32)\n",
        "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
        "\n",
        "        # 5. calculate all losses\n",
        "        xy_loss = obj_mask * box_loss_scale * \\\n",
        "            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
        "        wh_loss = obj_mask * box_loss_scale * \\\n",
        "            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
        "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
        "        obj_loss = obj_mask * obj_loss + \\\n",
        "            (1 - obj_mask) * ignore_mask * obj_loss\n",
        "        # TODO: use binary_crossentropy instead\n",
        "        class_loss = obj_mask * sparse_categorical_crossentropy(\n",
        "            true_class_idx, pred_class)\n",
        "\n",
        "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
        "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
        "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
        "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
        "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
        "\n",
        "        return xy_loss + wh_loss + obj_loss + class_loss\n",
        "    return yolo_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2kfyCsDiDos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义yolo_anchors和yolo_anchor_masks\n",
        "\n",
        "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
        "                         (59, 119), (116, 90), (156, 198), (373, 326)],\n",
        "                        np.float32) / 416\n",
        "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvWsY7Cahitb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 选定设备\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "physical_devices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Ls_KUzpfRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 加载模型，anchor以及anchor_masks\n",
        "\n",
        "model = YoloV3(FLAGS.size, training=True, classes=FLAGS.num_classes,channels=3,anchors=yolo_anchors,masks=yolo_anchor_masks)\n",
        "anchors = yolo_anchors\n",
        "anchor_masks = yolo_anchor_masks\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4GVokpUiq89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 加载训练集\n",
        "\n",
        "train_dataset = dataset.load_tfrecord_dataset(\n",
        "    FLAGS.dataset, FLAGS.classes, FLAGS.size)\n",
        "\n",
        "# 预处理训练集\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=512)\n",
        "train_dataset = train_dataset.batch(FLAGS.batch_size)\n",
        "train_dataset = train_dataset.map(lambda x, y: (\n",
        "    dataset.transform_images(x, FLAGS.size),\n",
        "    dataset.transform_targets(y, anchors, anchor_masks, FLAGS.size)))\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# 加载测试集\n",
        "\n",
        "val_dataset = dataset.load_tfrecord_dataset(\n",
        "            FLAGS.val_dataset, FLAGS.classes, FLAGS.size)\n",
        "\n",
        "# 预处理测试集\n",
        "\n",
        "val_dataset = val_dataset.batch(FLAGS.batch_size)\n",
        "val_dataset = val_dataset.map(lambda x, y: (\n",
        "    dataset.transform_images(x, FLAGS.size),\n",
        "    dataset.transform_targets(y, anchors, anchor_masks, FLAGS.size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kwW2VIvjZVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 开启Darknet的迁移学习\n",
        "# model = YoloV3(size = 416, channels=3,anchors=yolo_anchors,masks=yolo_anchor_masks, classes=80,training=True)\n",
        "model_pretrained = YoloV3(FLAGS.size, training=True, classes=FLAGS.weights_num_classes or FLAGS.num_classes, masks=yolo_anchor_masks,channels=3,anchors=yolo_anchors)\n",
        "model_pretrained.load_weights(FLAGS.weights)\n",
        "\n",
        "model.get_layer('yolo_darknet').set_weights(model_pretrained.get_layer('yolo_darknet').get_weights())\n",
        "freeze_all(model.get_layer('yolo_darknet'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcuwnCrijsDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 指定优化器和损失函数\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=FLAGS.learning_rate)\n",
        "\n",
        "loss = [YoloLoss(anchors[mask], classes=FLAGS.num_classes, ignore_thresh=0.5)\n",
        "        for mask in anchor_masks]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1APTWgdjxi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 编译及运行\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzlpPqQoqhjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(verbose=1),\n",
        "    EarlyStopping(patience=3, verbose=1),\n",
        "    ModelCheckpoint('checkpoints/yolov3_train_{epoch}.tf',\n",
        "                    verbose=1, save_weights_only=True),\n",
        "    TensorBoard(log_dir='logs')\n",
        "]\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=1,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=val_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpR_tL-2c-lQ",
        "colab_type": "text"
      },
      "source": [
        "### 非交互模式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buD9ZJBqdQUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tfrecord格式的数据集准备好即可\n",
        "\n",
        "!python train.py \\\n",
        "\t--dataset ./data/voc_train.tfrecord \\\n",
        "\t--val_dataset ./data/voc_val.tfrecord \\\n",
        "\t--classes ./data/voc2012.names \\\n",
        "\t--num_classes 20 \\\n",
        "\t--mode fit --transfer no_output \\\n",
        "\t--batch_size 16 \\\n",
        "\t--epochs 3 \\\n",
        "\t--weights ./checkpoints/yolov3.tf \\\n",
        "\t--weights_num_classes 80 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7OL0g6hwEU6",
        "colab_type": "text"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsLoOmx-wIhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAhkfVNjwN94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oim12Mwvcjaz",
        "colab_type": "text"
      },
      "source": [
        "## 加载权重查看训练效果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yx-U_r_UyLQU",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from absl import app, logging, flags\n",
        "from absl.flags import FLAGS\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (\n",
        "    YoloV3, YoloV3Tiny\n",
        ")\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ikR_jmnayP12",
        "colab": {}
      },
      "source": [
        "# flags.DEFINE_stirng 可以设定默认参数候选\n",
        "flags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\n",
        "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n",
        "                    'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('image', './data/girl.png', 'path to input image')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_string('output', './output.jpg', 'path to output image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "\n",
        "# 初始化程序\n",
        "app._run_init(['yolov3-detector'], app.parse_flags_with_usage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7ahz4xexV65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAGS.num_classes = 20\n",
        "FLAGS.classes = 'data/voc2012.names'\n",
        "FLAGS.weights = 'checkpoints/yolov3_train_1.tf'\n",
        "FLAGS.image = 'data/meme.jpg'\n",
        "\n",
        "# Lower threshold due to insufficient training\n",
        "FLAGS.yolo_iou_threshold = 0.2\n",
        "FLAGS.yolo_score_threshold = 0.2\n",
        "\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "logging.info('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "logging.info('classes loaded')\n",
        "\n",
        "img_raw = tf.image.decode_image(\n",
        "    open(FLAGS.image, 'rb').read(), channels=3)\n",
        "\n",
        "img = tf.expand_dims(img_raw, 0)\n",
        "img = transform_images(img, FLAGS.size)\n",
        "\n",
        "t1 = time.time()\n",
        "boxes, scores, classes, nums = yolo(img)\n",
        "t2 = time.time()\n",
        "logging.info('time: {}'.format(t2 - t1))\n",
        "\n",
        "logging.info('detections:')\n",
        "for i in range(nums[0]):\n",
        "    logging.info('\\t{}, {}, {}'.format(class_names[int(classes[0][i])],\n",
        "                                        np.array(scores[0][i]),\n",
        "                                        np.array(boxes[0][i])))\n",
        "\n",
        "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
        "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}